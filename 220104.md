# Learn OpenGL (2.9. Coordinates System)

#### 좌표 시스템

OpenGL은 각 vertex shader가 실행 된 후 모든 vertex들이 정규화된 디바이스 좌표(Normalized Device Coordinates, NDC)로 표시되기를 원한다. 즉 모든 vertex의 x, y, z 좌표가 -1.0~ 1.0 범위 안에 있어야 한다는 것을 의미하는데, 이 범위 밖의 좌표를 가진 vertex는 보이지 않게 된다.

일반적으로는 임의의 좌표계를 vertex shader에 전달하면 shader가 NDC좌표로 변환하는 작업을 수행하고, 이 NDC 좌표들은 rasterizer에 보내져 화면 위의 2D 좌표와 픽셀로 변환된다.

NDC로 좌표를 변환한 다음 스크린 좌표로 변환하는 것은 일반적으로 최종 스크린 좌표로 변환하기 전에 vertex를 여러 좌표 시스템으로 변환하는 단계적인 방법으로 수행한다.

이렇게 여러 중간 좌표 시스템으로 변환하여 얻는 장점으로는 일부 연산과 계산이 특정 좌표 시스템에서 수행하기 쉽기 때문이다. 중요한 좌표 시스템은 총 5가지가 있다.

* Local space
* World space
* View space
* Clip space
* Screen space

이들은 vertex가 변환되어 fragment가 되기 전까지는 모두 다른 상태이다.

#### Overview

하나의 공간에서 다음 좌표 공간으로 좌표를 변환하기 위해 여러가지 변환 행렬을 사용하는데, 이 중 가장 중요한 것들은 model, view, projection 행렬이다.

Vertex 좌표는 먼저 local 좌표를 사용하여 local 공간에서 시작하고 world, view, clip 좌표를 거쳐 최종적으로 screen 좌표로 변환된다.

![img](https://learnopengl.com/img/getting-started/coordinate_systems.png) 

1. Local 좌표는 오브젝트의 원점을 기준으로 한 좌표이며 모든 오브젝트의 처음 좌표이다.
2. 다음 단계는 local 좌표를 좀 더 큰 world에 대한 좌표인 world-space 좌표로 변환하는 것이다.
   이 좌표는 전체적인 world의 원점을 기준으로 하는 좌표이고, world의 원점을 기준으로 하기 때문에 더 많은 다른 오브젝트를 배치할 수 있다.
3. 그 다음 world 좌표를 각 좌표들이 카메라나 보는 사람의 시점에서 보이는 view-space좌표로 변환한다.
4. 좌표들이 view space로 변환되었으면 좌표들을 clip 좌표로 투영한다. Clip 좌표는 -1.0~1.0 범위로 처리되어 vertex들이 화면위에 그려지게 될 것인지 아닌지를 결정한다.
5. 그리고 마지막으로 viewport 변환이라 불리는 작업(-1.0~1.0 범위의 좌표들을 glViewport 함수를 통해 정의된 좌표 범위로 변환)을 통해 clip 좌표를 screen 좌표로 변환한다. 그리고 변환된 결과를 rasterizer로 보내져 fragment로 변환된다.

#### Local space

Local space는 오브젝트에 대한 좌표 공간이다.
모델의 모든 vertex는 local space에 있으며 이는 오브젝트를 기준으로 한다.

#### World space

각 오브젝트들을 더 큰 world에 배치하기 위해 각 오브젝트에 대한 위치를 정의하고자 하는 좌표계이다.
모든 vertex의 좌표는 game world를 기준으로 한다.

local space에서 world space로 변환하는 것은 model matrix를 사용하여 수행된다.

model matrix는 오브젝트를 그들이 속한 위치와 방향으로 world에 배치하기 위해 오브젝트를 이동, 스케일, 회전하는 변환 행렬이다.

#### View space

View space는 일반적으로 OpenGL에서의 카메라를 말하는 것이다.

View space는 world space 좌표를 유저의 시점 앞에 있는 좌표로 변환했을 때의 결과이다.
즉 카메라의 관점에서 바라보는 공간이라 할 수 있다.

일반적으로 scene을 이동/회전시키기 위해 이동과 회전의 조합을 사용하여 수행되며 특정 아이템이 카메라 앞으로 변환된다. 이러한 변환의 조합은 일반적으로 view matrix에 저장되고 view 행렬은 world좌표를 view 공간으로 변환한다.

#### Clip space

각 vertex shader 실행의 마지막에 OpenGL은 지정된 범위의 좌표를 받아들이고 이 범위 밖의 모든 좌표들은 잘린(clip)다. Clip된 좌표들은 폐기되고 남은 좌표들은 최종적으로 fragment가 되어 화면에 보이게 된다.

눈에 보이는 모든 좌표들을 -1.0과 1.0 범위 안으로 지정하는 것은 직관적이지 않기 때문에 우리는 임의의 좌표계를 정의하여 작업을 수행한 후 OpenGL이 원하는 NDC로 변환한다.

Vertex 좌표를 veiw에서 clip space로 변환하기 위해 우리는 좌표의 범위를 지정하는 project matrix라는 것을 정의한다. 그 다음 projection matrix는 이 지정된 범위에 있는 좌표들을 NDC로 변환하고 지정된 범위 밖의 좌표들은 매핑되지 않으므로 clip된다.

삼각형과 같은 primitive의 일부만 clipping volume에서 벗어낫다면 OpenGL은 clipping 범위에 맞도록 하나 이상의 삼각형을 재구성하게 된다. Projection matrix가 생성하는 viewing box는 절두체(frustum)이라 불리며 이 절두체 내부의 각 좌표들이 유저의 화면에 나타나게 된다.

이렇게 지정된 범위에서 NDC로 변환하는 전체적인 과정을 투영(projection)이라 부른다.

모든 vertex가 clip space로 변환되었다면 perspective division이라 불리는 마지막 작업이 수행된다.
여기에서 위치 벡터의 x, y, z를 w요소로 나누는데, 이 작업은 4D clip space 좌표를 3D NDC로 변환하는 작업이다.

이 단계 이후에 결과 좌표들을 screen 좌표에 매핑하고 fragment로 변환하는 것이다.

Projection 행렬은 view 좌표를 clip 좌표로 변환하기 위해 두개의 다른 형식을 받는데, 각 형식은 고유한 절두체를 가진다. 우리는 정사영(Orthographic) projection matrix와 원근(Perspective) projection matrix 중 하나를 선택할 수 있다.

* **Orthographic projection**
  정사영 투영 행렬은 정육면체와 같은 절두체 상자를 정의한다.
  이 절두체 상자는 이 상자 밖에 있는 vertex들을 clip하는 clipping 공간을 정의한다.
  Orthographic projection matrix를 생성할 때 눈에 보이는 절두체의 너비, 높이, 길이를 정의하고 이 절두체 내부의 vertex들은 clip되지 않는다.
  ![img](https://learnopengl.com/img/getting-started/orthographic_frustum.png) 
  이 절두체는 보이게 될 좌표들을 결정하고 너비와 높이, 가까운 평면과 먼 평면으로 이루어지는데, 가까운 평면 앞에 있는 모든 좌표들은 clip되고 먼 평면의 뒤에 있는 좌표들도 마찬가지로 clip된다.
  Orthographic 절두체는 절두체 내부에 있는 모든 좌표들을 NDC좌표로 직접 매핑하는데, 이는 각 벡터의 w요소를 건드리지 않기 때문이다. 만약 w 요소가 1.0이라면 perspective division은 좌표를 수정하지 않는다.

  Orthographic projection 행렬을 생성하기 위해 GLM의 glm::ortho 함수를 사용한다.

  ``` c++
  glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);
  ```

  처음 두 파라미터는 절두체의 왼쪽 오른족 좌표를 지정한다.
  세 네번째 파라미터는 절두체의 맨 밑과 맨 위의 좌표를 지정한다.
  그 다음 평면의 크기를 정의하고 가까운 평면과 먼 평면 사이의 거리를 정의한다.

  지정된 projection 행렬은 x, y, z 범위 값을 가진 모든 좌표들을 NDC로 변환한다.

  Orthogrphic projection matrix는 좌표들을 화면의 2D 평면에 똑바로 매핑하지만, 원근감을 고려하지 않은 비현실적인 결과를 보여준다. 이는 Perspective projection이 해결할 수 있다.

* **Perspective projection**
  실제 세상을 그래픽으로 보여주려면 멀리있는 오브젝트는 작아져야 한다.

  ![img](https://learnopengl.com/img/getting-started/perspective.png) 

  위 이미지처럼 원근법 때문에 선이 멀어질 수록 서로 만나고 있는데 이 것이 바로 perspective projection을 수행했을 때 얻을 수 있는 결과이다.

  Projection matrix는 주어진 절두체를 clip된 공간에 매핑할 뿐만 아니라 각 vertex좌표의 w 값을 조작한다.
  시점으로 부터 vertex 좌표가 멀어질수록 이 w 요소가 증가한다.

  좌표들이 clip space로 변환되고 나면 그들은 -w~w범위 안에 있게 되는데, 이 범위 밖의 모든 좌표는 clip되고 OpenGL은 veretx shader의 최종 출력으로 -1.0~1.0 범위 안에있는 좌표들만 보이게 한다.

  따라서 좌표들이 clip space에 있으면 perspective division은 clip space 좌표에 적용된다.

  ![image-20220104235352638](C:\Users\CYD\AppData\Roaming\Typora\typora-user-images\image-20220104235352638.png) 

  Vertex 좌표의 각 요소들은 w 요소로 나누어지는데, 시점에서 멀리 떨어진 vertex에게 작은 vertex 좌표를 준다. 이 것이 w 요소가 중요한 이유인데, perspective projection을 할 수 있도록 돕기 때문이다.

  perspective projection 행렬은 GLM에서 다음과 같이 생성할 수 있다.

  ``` c++
  glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f);
  ```

  glm::perspective 함수가 하는 일은 눈에 보이는 공간을 정의하는 큰 절두체를 생성하는 것이다.
  절두체 밖에 있는 모든 것은 clip space내부에 있지 않으므로 clip된다. perspective 절두체는 균일하지 않은 상자 모양으로 시각화 될 수 있는데, 이 상자 내부에 있는 각 좌표들이 clip space에 매핑된다.

  ![img](https://learnopengl.com/img/getting-started/perspective_frustum.png) 

  첫 번째 파라미터는 fov 값을 지정한다. fov는 field of view의 줄임말로 view space가 얼마나 큰지를 설정한다. 현실적인 시점을 위해서는 일반적으로 45도로 설정되지만 값을 조정함으로써 시야각을 넓히거나 줄일 수 있다.

  두 번째 파라미터는 view port의 넓이를 높이로 나눔으로써 계산되는 화면 비율을 설정한다.

  세번째, 네번째 파라미터는 가까운 평면과 먼 평면의 거리를 설정하는데, 일반적으로 가까운 평면과의 거리는 0.1f, 먼 평면의 거리는 100.0f로 설정한다. 가까운 평면과 먼 평면 사이에 있으면서 절두체 내부에 있는 vertex라면 렌더링 될 것이다.

  ###### * perspective 행렬의 가까운 평면의 값이 약간 큰 값으로 설정하는 경우 카메라와 가까운 모든 좌표들을 clip하는데, 일부 비디오 게임에서 오브젝트에 가까이 접근하는 경우 오브젝트를 뚫고 볼 수 있게 되는 화면을 생각해보면 쉽게 이해할 수 있다.

Orthographic project를 사용할 때 vertex의 각 요소는 똑바로 clip space에 매핑된다.
Orthographic projection은 perspective projection을 사용하지 않기 때문에 멀리 떨어진 오브젝트들이 작게 보이지 않는다. 이는 이상한 비주얼을 출력하기 대문에, 원근법에 의해 왜곡된 vertex들을 사용할 필요가 없는 2D 렌더링이나 일부 구조적이거나 공학적인 프로그램에서 사용된다. Blender와 같은 3D 모델링을 위한 프로그램은 모델링을 위해 종종 Orthographic projection을 사용하기도 한다.

![img](https://learnopengl.com/img/getting-started/perspective_orthographic.png) 

#### Putting it all together

앞서 언급한 각 단계에 필요한 변환 행렬들을 생성하고 다음과 같이 clip 좌표로 변환된다.

![image-20220105001237700](C:\Users\CYD\AppData\Roaming\Typora\typora-user-images\image-20220105001237700.png) 

행렬 곱셈의 순서는 반대임을 기억하자.
그런 다음 결과 veretx는 vertex shader의 gl_Position에 할당되어야 한다. 그런 다음 OpenGL은 perspective division과 clipping을 자동으로 수행할 것이다.

#### Going 3D

3D로 그리기 위해 먼저 model 행렬을 생성해야 한다. model 행렬은 vertex들을 world space로 변환하기 위한 이동, 스케일, 혹은 회전과 같은 변환들로 이루어져 있다. 평면을 x 축을 중심으로 조금 회전시켜 변환해보면 바닥에 누워있는 것 처럼 보일 것이다.

이 model 행렬은 다음과 같다.

``` c++
glm::mat4 model;
model = glm::rotate(model, glm::radians(-55.0f), glm::vec3(1.0f, 0.0f, 0.0f)); 
```

veretx 좌표를 이 model 행렬과 곱하면 vertex 좌표를 world 좌표로 변환할 수 있다.

다음엔 view 행렬을 생성해야 한다.
좀 더 뒤로 가서 오브젝트가 보이도록 하고 싶다면 OpenGL은 오른손 좌표계이기 때문에 시점의 위치를 z축의 양의 방향으로 이동해야 한다.

* **오른손좌표계**
  ![img](https://learnopengl.com/img/getting-started/coordinate_systems_right_handed.png) 

view 행렬은 다음과 같다.

``` c++
glm::mat4 view;
// 우리가 움직이고 싶은 방향과 반대의 방향으로 scene을 이동시키고 있다는 것을 알아두세요.
view = glm::translate(view, glm::vec3(0.0f, 0.0f, -3.0f)); 
```

오브젝트의 vertex를 변환하는 것이기 때문에 시점을 움직이고자 하는 방향의 반대로 이동시켜야 한다.

projection 행렬은 다음과 같다.

``` c++
glm::mat4 projection;
projection = glm::perspective(glm::radians(45.0f), screenWidth / screenHeight, 0.1f, 100.0f);
```

``` glsl
#version 330 core
layout (location = 0) in vec3 aPos;
...
uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;

void main()
{
    // 곱셈을 오른쪽에서 왼쪽으로 읽는다는 것을 알아두세요.
    gl_Position = projection * view * model * vec4(aPos, 1.0);
    ...
}
```

각 행렬을 받기 위해 vertex shader에 uniform 변수를 선언해주었다.

이제 이 행렬들을 shader에 uniform 변수에 전달해주면 아래와 같은 이미지를 얻을수 있다.

![image-20220105004001242](C:\Users\CYD\AppData\Roaming\Typora\typora-user-images\image-20220105004001242.png) 



#### More 3D

2D 평면을 이용하여 3D 공간에 오브젝트를 놓았다. 이제 이 2D 오브젝트를 3D 정육면체로 확장 해보자.

정육면체를 렌더링하기 위해서는 총 36개(6개의 면 * 2개의 삼각형 * 3개의 VERTEX)의 vertex가 필요하다.

``` c++ 
float vertices[] = {
-0.5f, -0.5f, -0.5f, 0.0f, 0.0f,
0.5f, -0.5f, -0.5f, 1.0f, 0.0f,
0.5f, 0.5f, -0.5f, 1.0f, 1.0f,
0.5f, 0.5f, -0.5f, 1.0f, 1.0f,
-0.5f, 0.5f, -0.5f, 0.0f, 1.0f,
-0.5f, -0.5f, -0.5f, 0.0f, 0.0f,
-0.5f, -0.5f, 0.5f, 0.0f, 0.0f,
0.5f, -0.5f, 0.5f, 1.0f, 0.0f,
0.5f, 0.5f, 0.5f, 1.0f, 1.0f,
0.5f, 0.5f, 0.5f, 1.0f, 1.0f,
-0.5f, 0.5f, 0.5f, 0.0f, 1.0f,
-0.5f, -0.5f, 0.5f, 0.0f, 0.0f,
-0.5f, 0.5f, 0.5f, 1.0f, 0.0f,
-0.5f, 0.5f, -0.5f, 1.0f, 1.0f,
-0.5f, -0.5f, -0.5f, 0.0f, 1.0f,
-0.5f, -0.5f, -0.5f, 0.0f, 1.0f,
-0.5f, -0.5f, 0.5f, 0.0f, 0.0f,
-0.5f, 0.5f, 0.5f, 1.0f, 0.0f,
0.5f, 0.5f, 0.5f, 1.0f, 0.0f,
0.5f, 0.5f, -0.5f, 1.0f, 1.0f,
0.5f, -0.5f, -0.5f, 0.0f, 1.0f,
0.5f, -0.5f, -0.5f, 0.0f, 1.0f,
0.5f, -0.5f, 0.5f, 0.0f, 0.0f,
0.5f, 0.5f, 0.5f, 1.0f, 0.0f,
-0.5f, -0.5f, -0.5f, 0.0f, 1.0f,
0.5f, -0.5f, -0.5f, 1.0f, 1.0f,
0.5f, -0.5f, 0.5f, 1.0f, 0.0f,
0.5f, -0.5f, 0.5f, 1.0f, 0.0f,
-0.5f, -0.5f, 0.5f, 0.0f, 0.0f,
-0.5f, -0.5f, -0.5f, 0.0f, 1.0f,
-0.5f, 0.5f, -0.5f, 0.0f, 1.0f,
0.5f, 0.5f, -0.5f, 1.0f, 1.0f,
0.5f, 0.5f, 0.5f, 1.0f, 0.0f,
0.5f, 0.5f, 0.5f, 1.0f, 0.0f,
-0.5f, 0.5f, 0.5f, 0.0f, 0.0f,
-0.5f, 0.5f, -0.5f, 0.0f, 1.0f
};
```

추가로 시간이 지남에 따라 정육면체를 회전시켜 볼 것이다.

``` c++
model = glm::rotate(model, (float)glfwGetTime() * glm::radians(50.0f), glm::vec3(0.5f, 1.0f, 0.0f));  
```

그런 다음 glDrawArrays 함수를 사용해 정육면체를 그릴 것이고 이번에는 36개의 vertex를 사용한다.

``` c++
glDrawArrays(GL_TRIANGLES, 0, 36);
```

추가로 vertex의 attribute가 변경되었으므로 shader를 수정하고 vap를 수정해주어야 한다.

그러면 아래와 같은 이미지를 얻을 수 있다.

![rotcube](C:\Users\CYD\Desktop\rotcube.gif) 

정육면체가 꽤 그럴듯하게 만들어졌지만, 정육면체의 일부 면들이 다른 면들 위로 그려진다.
OpenGL이 삼각형 단위로 그리기 때문에 생기는 문제인데, OpenGL은 깊이 정보를 z-buffer라 불리는 버퍼에 저장한다. 이 버퍼는 OpenGL이 픽셀 위에 그릴지 말지를 결정하게 해주고 z-buffer를 사용하면 OpenGL이 depth-testing을 할 수 있도록 구성할 수 있다.

#### Z-Buffer

OpenGL은 이 z-버퍼에 모든 깊이 정보들을 저장한다. 이 버퍼는 깊이 버퍼라고도 부르는데, GLFW는 이와 같은 버퍼를 자동으로 생성한다. 깊이는 각 fragment의 z값을 저장하고, fragment가 출력되길 원할 때 마다 OpenGL은 해당 깊이 값과 z-버퍼를 비교하고 만약 현재 fragment가 다른 fragment의 뒤에 있다면 폐기하며 앞에 있다면 덮어 씌운다. 이 과정을 depth testing이라 부르며 OpenGL에 의해 자동적으로 수행된다.

OpenGL은 depth testing이 기본적으로 사용하지 않도록 되어있기 때문에 glEnable 함수를 사용하여 수행하도록 만들어 주어야 한다.

glEnable과 glDisable은 OpenGL에서 특정 기능에 대해 사용 여부를 설정하는 함수이다.

``` c++
glEnable(GL_DEPTH_TEST);
```

깊이 버퍼는 루프가 돌 때 마다 비워주어야 한다.

``` c++
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
```

![rotcubegood](C:\Users\CYD\Desktop\rotcubegood.gif) 

성공적으로 잘 출력되는 것을 볼 수 있다.

#### More Cubes!

만약 화면에 10개의 정육면체를 출력하길 원한다고 해보자.
각 정육면체는 똑같이 생겼겠지만, world에서의 위치와 회전이 다를 것이다.

정육면체의 그래픽 레이아웃은 이미 정의되어 있으므로 더 많은 오브젝트를 렌더링할 때 버퍼나 attribute 배열들을 수정할 필요가 없다.

각 오브젝트에 대해 우리가 수정해야할 단 한가지는 정육면체를 world로 변환할 그들의 model 행렬이다.

먼저 각 정육면체에 대해 이동 벡터를 정의하여 world space에서 그들의 위치를 지정하자.

``` c++
glm::vec3 cubePositions[] = {
  glm::vec3( 0.0f,  0.0f,  0.0f), 
  glm::vec3( 2.0f,  5.0f, -15.0f), 
  glm::vec3(-1.5f, -2.2f, -2.5f),  
  glm::vec3(-3.8f, -2.0f, -12.3f),  
  glm::vec3( 2.4f, -0.4f, -3.5f),  
  glm::vec3(-1.7f,  3.0f, -7.5f),  
  glm::vec3( 1.3f, -2.0f, -2.5f),  
  glm::vec3( 1.5f,  2.0f, -2.5f), 
  glm::vec3( 1.5f,  0.2f, -1.5f), 
  glm::vec3(-1.3f,  1.0f, -1.5f)  
};
```

이제 게임 루프 안에서 glDrawArrays 함수를 10번 호출하면 된다.

이번에는 렌더링할 때마다 다른 model 행렬을 vertex shader에게 보냄으로써 새로운 정육면체가 렌더링될 때마다 model 행렬을 수정한다.

``` c++
for (unsigned int i = 0; i < 10; i++)
{
	glm::mat4 model = glm::mat4(1.0f);
	model = glm::translate(model, cubePositions[i]);
	float angle = 20.0f * i;
	model = glm::rotate(model, (float)glfwGetTime() * glm::radians(angle), glm::vec3(1.0f, 0.3f, 0.5f));
	ourShader.setMat4("model", model);

	glDrawArrays(GL_TRIANGLES, 0, 36);
}
```

위 반복문은 렌더링 루프 내부에 작성한다.

![chaos](C:\Users\CYD\Desktop\chaos.gif)

실제로 오브젝트는 가만히 있지만 model matrix의 수정만으로 움직이는 오브젝트를 만들었다.
회전 속도를 i 값에 비례하도록 작성했기 때문에 정지~빠른속도로 회전하는 오브젝트를 확인할 수 있다.